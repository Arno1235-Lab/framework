services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow_tracking
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow.db
      - MLFLOW_ARTIFACTS_DESTINATION=/mlflow/artifacts
    volumes:
      - ./mlflow/data:/mlflow
      - ./mlflow/logs:/logs
    command:
      - mlflow
      - server
      - --backend-store-uri=sqlite:///mlflow.db
      - --default-artifact-root=/mlflow/artifacts
      - --host=0.0.0.0
    restart: always

  # Python ML Development Container
  ml_dev_py:
    runtime: nvidia
    environment:
        - NVIDIA_VISIBLE_DEVICES=all
        - MLFLOW_TRACKING_URI=http://mlflow:5000
        - CUDA_HOME=/usr/local/cuda
        - PATH=/usr/local/cuda/bin:$PATH
        - LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}
    volumes:
        - ${WORKSPACE_PATH:-./workspace}:/workspace
        - ./workspace:/workspace/default
        - ${HOME}/.ssh:/root/.ssh:ro
    deploy:
        resources:
        reservations:
            devices:
            - driver: nvidia
                count: all
                capabilities: [gpu]
    build:
      context: .
      dockerfile: dockerfile
      args:
        - PYTHON_VERSION=${PYTHON_VERSION}
    container_name: ml_dev_py
    image: ml_dev_py

volumes:
  mlflow_data:
